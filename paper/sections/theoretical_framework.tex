This study presents a comprehensive methodological framework for the detection of hate speech on Twitter, integrating both machine learning and deep learning approaches. The process began with an extensive data preprocessing pipeline to ensure data consistency, clean noisy text, and address class imbalance using Easy Data Augmentation (EDA)~\cite{wei2019eda}. This included standard text normalization techniques—such as stopword removal and stemming—as well as more advanced steps like automated spelling correction and synonym expansion.

Subsequently, multiple classification models were implemented and evaluated. For traditional machine learning, models such as Support Vector Machines (SVM), Logistic Regression, and Multinomial Naive Bayes were applied, providing baseline performances and interpretability advantages. On the deep learning side, we implemented architectures including Convolutional Neural Networks (CNN) and Gated Recurrent Units (GRU), both trained on pretrained embeddings to capture contextual linguistic features.

In addition, transformer-based language models were explored, notably RoBERTa, for which both zero-shot evaluation and supervised fine-tuning were performed. The fine-tuning involved training a classification head on top of RoBERTa’s pretrained layers using our balanced dataset.

This comparative methodology allows for a fair assessment across heterogeneous architectures, evaluating their strengths and limitations under a consistent experimental setup inspired by previous works~\cite{fieri2023offensive,almeida2023comparison}.

\subsection{Machine learning Methods}
This section describes the classification methods used in this study. Each represents a different approach within supervised learning.

\input{sections/contex/logisticregression_contex.tex}
\input{sections/contex/naive_bayes_contex.tex}
\input{sections/contex/svm_contex.tex}
\input{sections/contex/xgboost_contex.tex}

\subsection{Deep Learning Methods}
Deep learning is a subset of machine learning that uses artificial neural networks with many layers to automatically learn complex patterns from large amounts of data.

\input{sections/contex/mlp_contex.tex}
\input{sections/contex/cnn_contex.tex}
\input{sections/contex/bi_lstm_contex.tex}
\input{sections/contex/gru_contex.tex}
\input{sections/contex/roberta_contex.tex}
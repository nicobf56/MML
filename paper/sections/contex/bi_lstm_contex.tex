\subsubsection{BI-LSTM}

\noindent
\cite{toktarova2023hate} BI-LSTM (Bidirectional Long Short-Term Memory) is a type of sequential neural network that allows working with data composed of different elements ordered in a sequence, such as text. This type of network can make predictions about parts of the sequence based on what has been seen so far or on the entire input. It is an improvement over LSTM networks, which, like recurrent networks, use output values from previous steps in the sequence. However, it differs by dividing the network's responsibilities into different flow control gates. Additionally, it is capable of maintaining both long-term memory and a hidden state, which allows it to respond appropriately to the current step in the sequence. BI-LSTMs process the input both forward and backward, thus capturing future and past context at each step. In \cite{toktarova2023hate}, using BI-LSTM, an accuracy of 90.2 was achieved; meanwhile, in \cite{fieri2023offensive}, 96.102 was reached.

